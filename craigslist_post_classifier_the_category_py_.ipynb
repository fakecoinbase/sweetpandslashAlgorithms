{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "craigslist_post_classifier_the_category.py .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTG02J9uIrGAlZdShAgAmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetpand/Algorithms/blob/master/craigslist_post_classifier_the_category_py_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97XrfrGqvzO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import fileinput\n",
        "\n",
        "#######Extract the Testing data\n",
        "i=-1\n",
        "testing_data=[]\n",
        "for line in fileinput.input():\n",
        "    if i==-1:\n",
        "        no_test=int(line.split(\" \")[0])\n",
        "        i=i+1\n",
        "    else:\n",
        "        testing_data.append(json.loads(line))\n",
        "testing_feature= [x['heading'].lower() for x in testing_data]\n",
        "\n",
        "#######Extract the Training data\n",
        "\n",
        "data = []\n",
        "with open('training.json') as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "        \n",
        "training_feature =[x['heading'].lower() for x in data[1:]]\n",
        "training_topics = [x['category'] for x in data[1:]]\n",
        "\n",
        "#######Extract the unique topics and assign a class i.e number corresponding to each topic\n",
        "unique_training =list(set(training_topics))\n",
        "training_set = {}\n",
        "training_inverse_set = {}\n",
        "count=0\n",
        "for x in unique_training:\n",
        "    count=count+1\n",
        "    training_set[x]=count\n",
        "    training_inverse_set[count] = x\n",
        "    \n",
        "#######Build the Model      \n",
        "max_range=1\n",
        "training_class = [training_set[x] for x in training_topics]\n",
        "vectorizer = TfidfVectorizer(max_df=1.0, ngram_range=(1,max_range),stop_words='english', use_idf='True')\n",
        "vectorized_feature = vectorizer.fit_transform(training_feature)\n",
        "model = MultinomialNB().fit(vectorized_feature, training_class)\n",
        "\n",
        "#######Predict the Output\n",
        "vectorized_feature_test = vectorizer.transform(testing_feature)\n",
        "prediction = model.predict(vectorized_feature_test)\n",
        "for each_prediction in prediction:\n",
        "    print training_inverse_set[each_prediction]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}