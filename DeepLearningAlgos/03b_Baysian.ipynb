{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Baysian.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt3CQFwQ3IE_",
        "colab_type": "text"
      },
      "source": [
        "# Baysian Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93zkQS0j3Lx1",
        "colab_type": "text"
      },
      "source": [
        "Form of hyper-parameter tuning.\n",
        "\n",
        "Example of using something designed for pytorch in fastai\n",
        "\n",
        "Repository for Today: [BayesianOptimization](https://github.com/fmfn/BayesianOptimization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNvrk43w6ip4",
        "colab_type": "text"
      },
      "source": [
        "## How does it work?\n",
        "\n",
        "Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below.\n",
        "\n",
        "![](https://github.com/fmfn/BayesianOptimization/raw/master/examples/bo_example.png)\n",
        "\n",
        "- Taken from their github readme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiD9STjY20F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "d12563da-25ab-4b9a-8f3a-6147d01e30e6"
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10031 sha256=bf519bbd7268a6d30ad9b7ca7c245ebfb97b3d7f8e6c0b98f5cfe700ae7791d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFlERfSP3TWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.tabular import *\n",
        "from bayes_opt import BayesianOptimization\n",
        "from fastprogress import *\n",
        "from fastai.utils.mod_display import progress_disabled_ctx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D8nzBRi3f0l",
        "colab_type": "text"
      },
      "source": [
        "For today's example, we will use the Adults problem and adjust weight decay, learning rate, and drop out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpovbsU13e9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5v_MqFz3oCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dep_var = 'salary'\n",
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia4XvVKP3rUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                           .split_by_idx(list(range(800,1000)))\n",
        "                           .label_from_df(cols=dep_var)\n",
        "                           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-P3m3Nt3wde",
        "colab_type": "text"
      },
      "source": [
        "Next we need to define a `fit_with` function, where our inputs will be whatever we want to test our hyperparemeters on, essentially you can adjust *anything* in here. For us, we only care about how hyperparemeters dealing with our model do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA88zN693tVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_with(lr:float, wd:float, dp:float):\n",
        "  # create a Learner\n",
        "  learn = tabular_learner(data, layers=[200,100], metrics=accuracy, emb_drop=dp, wd=wd)\n",
        "  \n",
        "  # Train for x epochs\n",
        "  with progress_disabled_ctx(learn) as learn:\n",
        "    learn.fit_one_cycle(3, lr)\n",
        "    \n",
        "  # Save, print, and return the overall accuracy\n",
        "  acc = float(learn.validate()[1])\n",
        "  \n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Achkku4cCn",
        "colab_type": "text"
      },
      "source": [
        "Finally, we need to determine what our ranges for our hyperparameters need to be as a dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUdC42Z4bqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hps = {'lr': (1e-05, 1e-02),\n",
        "      'wd': (4e-4, 0.4),\n",
        "      'dp': (0.01, 0.5)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Lkcl0b42gB",
        "colab_type": "text"
      },
      "source": [
        "Now we can build our optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKT9Zlp74zjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = BayesianOptimization( \n",
        "    f = fit_with, # our function\n",
        "    pbounds=hps, # our boundaries\n",
        "    verbose=2, # 1 prints a maximum only when observed, 0 is silent\n",
        "    random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD1nhhk46UOb",
        "colab_type": "text"
      },
      "source": [
        "And now we do a search!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBfEqU6H5Qy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cbbd653c-73ae-46c6-8c00-678fddee00a4"
      },
      "source": [
        "%time optim.maximize(n_iter=10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.835   \u001b[0m | \u001b[0m 0.2231  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.3484  \u001b[0m |\n",
            "=============================================================\n",
            "CPU times: user 3min 33s, sys: 30.2 s, total: 4min 3s\n",
            "Wall time: 3min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHAkjSfd62zJ",
        "colab_type": "text"
      },
      "source": [
        "Now let's look at our best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WclmLG2z5USl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28d65e45-65df-4e53-c3e9-8bd230ac39d2"
      },
      "source": [
        "print(optim.max)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'target': 0.8349999785423279, 'params': {'dp': 0.2740201996616449, 'lr': 0.004197753198888915, 'wd': 0.27421371235854514}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFkiYg5e7C6O",
        "colab_type": "text"
      },
      "source": [
        "We can also look at all of our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOfGifnm68Zu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "9f9b2f49-00e7-41fb-c2e2-9630e593b6ad"
      },
      "source": [
        "for i, res in enumerate(optim.res):\n",
        "  print('Iteration {} \\n\\t{}'.format(i, res))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \n",
            "\t{'target': 0.824999988079071, 'params': {'dp': 0.21434078230426126, 'lr': 0.007206041689487159, 'wd': 0.00044570417701101674}}\n",
            "Iteration 1 \n",
            "\t{'target': 0.8149999976158142, 'params': {'dp': 0.1581429605896015, 'lr': 0.0014760913492629594, 'wd': 0.0372985024696116}}\n",
            "Iteration 2 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.10126750357505873, 'lr': 0.0034621516631600474, 'wd': 0.15894828270257572}}\n",
            "Iteration 3 \n",
            "\t{'target': 0.8349999785423279, 'params': {'dp': 0.2740201996616449, 'lr': 0.004197753198888915, 'wd': 0.27421371235854514}}\n",
            "Iteration 4 \n",
            "\t{'target': 0.824999988079071, 'params': {'dp': 0.11018160236844353, 'lr': 0.008782393189545545, 'wd': 0.011344082241891295}}\n",
            "Iteration 5 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.5, 'lr': 0.01, 'wd': 0.4}}\n",
            "Iteration 6 \n",
            "\t{'target': 0.824999988079071, 'params': {'dp': 0.3385290799874171, 'lr': 0.004178874975647598, 'wd': 0.2236524554469224}}\n",
            "Iteration 7 \n",
            "\t{'target': 0.8100000023841858, 'params': {'dp': 0.07878959991166454, 'lr': 0.0019890338759579393, 'wd': 0.32037752964274446}}\n",
            "Iteration 8 \n",
            "\t{'target': 0.8149999976158142, 'params': {'dp': 0.4844481721025048, 'lr': 0.003141107539810836, 'wd': 0.27705211722145795}}\n",
            "Iteration 9 \n",
            "\t{'target': 0.824999988079071, 'params': {'dp': 0.4394306846250588, 'lr': 0.008947120568403435, 'wd': 0.03438366686336325}}\n",
            "Iteration 10 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.029136843784112354, 'lr': 0.0017066058914500435, 'wd': 0.3513057443703935}}\n",
            "Iteration 11 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.3109234184704589, 'lr': 0.01, 'wd': 0.4}}\n",
            "Iteration 12 \n",
            "\t{'target': 0.6600000262260437, 'params': {'dp': 0.01, 'lr': 1e-05, 'wd': 0.0004}}\n",
            "Iteration 13 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.5, 'lr': 0.01, 'wd': 0.0004}}\n",
            "Iteration 14 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.06992043366184122, 'lr': 0.01, 'wd': 0.4}}\n",
            "Iteration 15 \n",
            "\t{'target': 0.8299999833106995, 'params': {'dp': 0.5, 'lr': 0.01, 'wd': 0.13414236271019292}}\n",
            "Iteration 16 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.2109149821872044, 'lr': 0.01, 'wd': 0.16439313383002094}}\n",
            "Iteration 17 \n",
            "\t{'target': 0.8299999833106995, 'params': {'dp': 0.01, 'lr': 0.01, 'wd': 0.2502516509945325}}\n",
            "Iteration 18 \n",
            "\t{'target': 0.8199999928474426, 'params': {'dp': 0.37616126312596776, 'lr': 0.01, 'wd': 0.31599268719972023}}\n",
            "Iteration 19 \n",
            "\t{'target': 0.824999988079071, 'params': {'dp': 0.01, 'lr': 0.01, 'wd': 0.4}}\n",
            "Iteration 20 \n",
            "\t{'target': 0.8349999785423279, 'params': {'dp': 0.2231423431471948, 'lr': 0.01, 'wd': 0.3484051374580442}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
