{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial on SPAM detection using fastai ULMFiT - Part 2: Classification Model",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetpand/Algorithms/blob/master/Tutorial_on_SPAM_detection_using_fastai_ULMFiT_Part_2_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsMgf8LLsoOq",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial on SPAM detection using fastai ULMFiT - Part 2: Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkLEr18yWf7J",
        "colab_type": "text"
      },
      "source": [
        "tl;dr: This post is about how to create a classification model using a pre-trained and fine-tuned **language model**, all from the great `fastai` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lguNggZy249r",
        "colab_type": "text"
      },
      "source": [
        "This post is the continuation of [Tutorial on SPAM detection using fastai ULMFiT - Part 1: Language Model](https://drive.google.com/drive/u/0/folders/13uo91qC4cUFPepeRCg5XXoBCFqg3Q2Mn).  \n",
        "\n",
        "We are going to quickly replicate all from post 1. \n",
        "And yes, it is less expensive than loading the trained **language model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-mYNWDBB4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing torch_nightly and fastai \n",
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html  gwpy &> /dev/null\n",
        "!pip install fastai  gwpy &> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA87AbrrBigr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "\n",
        "from fastai import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os\n",
        "from fastai.text import *\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz5vzTnsCf5H",
        "colab_type": "text"
      },
      "source": [
        "Download SPAM data from UCI repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQf44JDCK7td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip smsspamcollection.zip\n",
        "\n",
        "df1 = pd.read_csv('SMSSpamCollection', sep='\\t',  header=None, names=['target', 'text'])\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df1, stratify = df1['target'], test_size = 0.3, random_state = 999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSyAKnzV7aSJ",
        "colab_type": "text"
      },
      "source": [
        "Now we replicate the creation of the language model with the same parameters as Part 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_yhSNeF7ZdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "lang_mod = language_model_learner(data_lm,  arch = AWD_LSTM, pretrained = True, drop_mult=1.)\n",
        "\n",
        "lang_mod.fit_one_cycle(4, max_lr= 5e-02)\n",
        "lang_mod.freeze_to(-1)\n",
        "lang_mod.fit_one_cycle(3, slice(1e-2/(2.6**4), 1e-2))\n",
        "lang_mod.freeze_to(-2)\n",
        "lang_mod.fit_one_cycle(3, slice(3e-3/(2.6**4), 1e-3))\n",
        "lang_mod.unfreeze()\n",
        "lang_mod.fit_one_cycle(3, slice(3e-3/(2.6**4), 1e-3))\n",
        "\n",
        "lang_mod.save_encoder('my_awsome_encoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwpBspEx0jAK",
        "colab_type": "text"
      },
      "source": [
        "### POST STARTS HERE! The Clasification Model ⚡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg3IDbs-1JIX",
        "colab_type": "text"
      },
      "source": [
        "Same as before, we create a data bunch with the needed information for the classication.\n",
        "\n",
        "Note the `vocab` parameter comes from the data used in the language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvFWWM4ljoH",
        "colab_type": "text"
      },
      "source": [
        "#### Data for *Classification Model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tNP_aMTEOKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn,  valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qa9y0l1ZT7",
        "colab_type": "text"
      },
      "source": [
        "Check the batch data, now we have `text` + `target` columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N7gP3LxxAaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo2HRD0_qf34",
        "colab_type": "text"
      },
      "source": [
        "Let's create the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSkXI7HJET_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier = text_classifier_learner(data_clas, drop_mult=0.7, arch = AWD_LSTM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dov4xQCO1mE-",
        "colab_type": "text"
      },
      "source": [
        "Next, we load the encoder (language model) \"we did\" in Part 1 to the classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjJOmveM8clP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.load_encoder('my_awsome_encoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x_hyFSk3UJ5",
        "colab_type": "text"
      },
      "source": [
        "### Training the language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VwFYmH33WmS",
        "colab_type": "text"
      },
      "source": [
        "![Training a deep learning](https://blog.datascienceheroes.com/content/images/2019/12/tweaking-NN.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCwkCHKb2udz",
        "colab_type": "text"
      },
      "source": [
        "📌 Similar to what we did with the language model, the steps are:\n",
        "\n",
        "\n",
        "1. Find the best learning rate (LR)\n",
        "2. Adjust the last layer with the `fit_one_cycle` funciton\n",
        "3. Unfreeze all the layers\n",
        "4. Find again the new LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VaunwDAMmLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.lr_find()\n",
        "learn_classifier.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7GTTw1GMl2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.fit_one_cycle(5, max_lr=1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FVJVdqZnvU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK0CoRBm672G",
        "colab_type": "text"
      },
      "source": [
        "Now we unfreeze one more layer, and then we find the new LR:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWUyOEKOjYh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_mod.freeze_to(-1)\n",
        "\n",
        "learn_classifier.lr_find()\n",
        "learn_classifier.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B66WsYa7Dit",
        "colab_type": "text"
      },
      "source": [
        "Hmmm depending on the run, the min suggested point might not be the ideal one. The objective is to find a LR prior to the loss divergence.\n",
        "\n",
        "Note: After some testing, it was not possible to improve the last performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdiBYgZGdqSD",
        "colab_type": "text"
      },
      "source": [
        "### Playing with the classifier! \n",
        "\n",
        "![Testing the algorithm](https://media.giphy.com/media/l2R0duZtUJWZjN2ko/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X74EfK3VffL6",
        "colab_type": "text"
      },
      "source": [
        "Trying a non-spam text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46tIbe5ztm0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.predict('did you buy the groceries for dinner? :)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VNaznOyfwI1",
        "colab_type": "text"
      },
      "source": [
        "We gott the prediction label `ham`, prediction value `0`, and the tensor of probabilities associtated with the softmax function ~ `[0.998, 0.002]`.\n",
        "\n",
        "Where: 0.998=99.8%, is the likelihood for non-spam given the text. And 0.33% is the likelihood of non-spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wXdsoS3gQbe",
        "colab_type": "text"
      },
      "source": [
        "Now some try with a **suspicious** spam text. \n",
        "Following text is similar to one shown in the training data, but slighlty different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukzaMTlCfaYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.predict('Free entry call back now')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aoB81BAgdL7",
        "colab_type": "text"
      },
      "source": [
        "Now the classification is what we expected, 82% of chances to be **spam** 🕵️‍♀️\n",
        "\n",
        "Homework! Try to write some phrases using some of the words that appear on SPAM messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJR_b8iyh1Oy",
        "colab_type": "text"
      },
      "source": [
        "####  A side note about the exploratory data analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S2Uvzrg1-J",
        "colab_type": "text"
      },
      "source": [
        "It's interesting what comes from a quick inspeciton on the SPAM data:\n",
        "\n",
        "1. Lots of messages are using capital case\n",
        "2. Lots of messages are using telefono numbers to reply the SMS.\n",
        "\n",
        "Align to this, we can test the same message as before, and we can check that adding a number increases the likelihood, for the same text message, to be spam:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YMIEnr2B1-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_classifier.predict('Free entry call back now 0393029442')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yEdzFlxikBM",
        "colab_type": "text"
      },
      "source": [
        "The SPAM likelihood incresead from 82% to 92%! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E0G0ZFZisRd",
        "colab_type": "text"
      },
      "source": [
        "### Validating the Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP2tloL42H7U",
        "colab_type": "text"
      },
      "source": [
        "Getting the predictions from the validation data, ordered, so we can use it late."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mqNhQobomQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_preds, valid_label=learn_classifier.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
        "valid_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IYw4WZ-jb4M",
        "colab_type": "text"
      },
      "source": [
        "Unexpectedly, if we do the same for the train data, google colab crashes, that's why it's commented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h_Y249acqOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_preds, train_label=learn_classifier.get_preds(ds_type=DatasetType.Train, ordered=True)\n",
        "#train_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCxNBAoHuZQD",
        "colab_type": "text"
      },
      "source": [
        "_Does anyone know why?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs6v6d58koZ6",
        "colab_type": "text"
      },
      "source": [
        "#### Setting the threshold for SPAM data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj074gEX3Vkq",
        "colab_type": "text"
      },
      "source": [
        "First we check the average ratio (prior) for each category:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLg8uk9x_STa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=valid_preds.numpy()\n",
        "print(np.mean(preds[:,0]))\n",
        "print(np.mean(preds[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlWAEKMdjx1K",
        "colab_type": "text"
      },
      "source": [
        "89% is non-spam.\n",
        "\n",
        "11% is spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3_NTnbzj7Ln",
        "colab_type": "text"
      },
      "source": [
        "These ratios are an important starting point to set the minimum threshold for which we flag the message as spam. \n",
        "\n",
        "`predict` function will assign the label based on a threshold based on 0.5. \n",
        "This is not optimized for the classification task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njo3ryRlk21w",
        "colab_type": "text"
      },
      "source": [
        "#### Testing the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hqmrwBe3cV7",
        "colab_type": "text"
      },
      "source": [
        "In order to be conservative, and reduce the false positive rate (so common in this type of anomaly data projects), the threshold value for the SPAM category will be `0.05`.\n",
        "\n",
        "All above 0.05 will be flagged as spam.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsVKysLs86f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_target=preds[:,1]>0.05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wueqv5i36VZ",
        "colab_type": "text"
      },
      "source": [
        "We build the final data frame to test the results:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX5_0Xt7rR3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_val_pred=pd.DataFrame({'text':df_val.text, 'target':df_val.target, 'pred_target':val_target, 'spam_score':preds[:,1]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY_1A3MRlYjE",
        "colab_type": "text"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDn5umpmrCEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_val_pred.target, df_val_pred.pred_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVbAGT7URga4",
        "colab_type": "text"
      },
      "source": [
        "Not so bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6-ORSkvl2_t",
        "colab_type": "text"
      },
      "source": [
        "**Sanity check**: check the score against some cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_DYOTyQtbKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_val_pred.sort_values(['target','pred_target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liQLTPpi4R8z",
        "colab_type": "text"
      },
      "source": [
        "#### ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk0kALaxmCGX",
        "colab_type": "text"
      },
      "source": [
        "The go-to testing methods for two-class target, the ROC curve (specially useful in non-balanced data sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb28CRGxmrPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from matplotlib import pyplot\n",
        "\n",
        "df_val_pred['target_binary'] = np.where(df_val_pred['target'].str.contains('spam'), 1, 0)\n",
        "\n",
        "lr_probs = df_val_pred.spam_score\n",
        "\n",
        "# calculate scores\n",
        "lr_auc = roc_auc_score(df_val_pred.target_binary, lr_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(df_val_pred.target_binary, lr_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvlAj_aDtped",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the roc curve for the model\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ULMFiT')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF6NaNQAmVD8",
        "colab_type": "text"
      },
      "source": [
        "Area Under Roc Curve (AUC):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JVTrdmRmZMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anWuV7P_mhm-",
        "colab_type": "text"
      },
      "source": [
        "Altough it seem too good to be truth, the AUC is 0.99.\n",
        "\n",
        "![alt text](https://blog.datascienceheroes.com/content/images/2019/12/not-bad-154.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4da3_jmmewA",
        "colab_type": "text"
      },
      "source": [
        "### Summing-up!\n",
        "\n",
        "\n",
        "The fastai library provides an intuitive and easy-to-use interface to create a text classifiaction model (among others), which takes advantage from the pre-trained ULMFiT model we saw in Part 1.\n",
        "\n",
        "The transfer learning techniques in NLP help us to quickly have a proven semantic base (pretrained model with millions of articles from wikipedia), in addition to being able to adjust it to our domain data just by running the fit_one_cycle function. An incredible job by the fastai team!\n",
        "\n",
        "### Continue learning\n",
        "\n",
        "Definitely, check the official documentation, well written and plenty of examples: [Efficient multi-lingual language model fine-tuning](https://nlp.fast.ai/)\n",
        "\n",
        "An example related to tweet classification: [Transfer Learning in NLP for Tweet Stance Classification](https://towardsdatascience.com/transfer-learning-in-nlp-for-tweet-stance-classification-8ab014da8dde?gi=451c25762288)\n",
        "\n",
        "A more technical article: [Understanding building blocks of ULMFIT](https://medium.com/mlreview/understanding-building-blocks-of-ulmfit-818d3775325b)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm3LPtqszIxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDA2AcLLmx_y",
        "colab_type": "text"
      },
      "source": [
        "Any questions or suggestions? Leave in the blog post comment section 📩\n",
        "\n",
        "\n",
        "### Get in touch!  🌎\n",
        "\n",
        "Found me at: [linkedin](https://www.linkedin.com/in/pcasas/) & [twitter](https://twitter.com/pabloc_ds) \n",
        "\n",
        "📗 [Data science Live Book](https://livebook.datascienceheroes.com) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G61PIonhZ7G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}